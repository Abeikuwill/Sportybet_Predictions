{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdRzhJpqf1XIYysHdI9xVe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e9c4030465045cf8a9189dfa9d03c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_628b021501094a09918365c4da08cba7",
              "IPY_MODEL_0105343a0a314fe5b31941812210759b",
              "IPY_MODEL_babbddbe95f94f999220666583fe907d"
            ],
            "layout": "IPY_MODEL_ab129f85a28249b7906fc6b3078c9cae"
          }
        },
        "628b021501094a09918365c4da08cba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41bedcba162e4cff8049e311b7fd8120",
            "placeholder": "​",
            "style": "IPY_MODEL_2d6a70ae66084313af6fac75595d989b",
            "value": "Map: 100%"
          }
        },
        "0105343a0a314fe5b31941812210759b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5885cfb78440589db8d6c682150e6c",
            "max": 1041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7414c9317054c38a0ce50becdd4501a",
            "value": 1041
          }
        },
        "babbddbe95f94f999220666583fe907d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771ab568dc5441b3817e582b7c76fe39",
            "placeholder": "​",
            "style": "IPY_MODEL_70732b6b0e674dc08638e32100a6d653",
            "value": " 1041/1041 [00:00&lt;00:00, 3541.94 examples/s]"
          }
        },
        "ab129f85a28249b7906fc6b3078c9cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bedcba162e4cff8049e311b7fd8120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6a70ae66084313af6fac75595d989b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f5885cfb78440589db8d6c682150e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7414c9317054c38a0ce50becdd4501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "771ab568dc5441b3817e582b7c76fe39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70732b6b0e674dc08638e32100a6d653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s4s1bEXQCRWF",
        "outputId": "583aaef5-d6f4-4e83-b239-8401a7b69373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936,
          "referenced_widgets": [
            "7e9c4030465045cf8a9189dfa9d03c15",
            "628b021501094a09918365c4da08cba7",
            "0105343a0a314fe5b31941812210759b",
            "babbddbe95f94f999220666583fe907d",
            "ab129f85a28249b7906fc6b3078c9cae",
            "41bedcba162e4cff8049e311b7fd8120",
            "2d6a70ae66084313af6fac75595d989b",
            "4f5885cfb78440589db8d6c682150e6c",
            "c7414c9317054c38a0ce50becdd4501a",
            "771ab568dc5441b3817e582b7c76fe39",
            "70732b6b0e674dc08638e32100a6d653"
          ]
        },
        "id": "9NcXSuo-50bL",
        "outputId": "f12bfa6f-e134-4bbd-e509-218f2a297691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Match Time                   HomeTeam                  AwayTeam  Home Score  \\\n",
            "0      04:00  Athletic Bilbao (Aladdin)        Real Madrid (Pele)           3   \n",
            "1      05:30  Athletic Bilbao (Aladdin)  Atletico Madrid (Xerxes)           1   \n",
            "2      05:45  Athletic Bilbao (Aladdin)           Girona FC (Val)           1   \n",
            "3      06:00  Athletic Bilbao (Aladdin)      FC Barcelona (Panic)           1   \n",
            "4      06:30     FC Barcelona (Aladdin)         Sl Benfica (Pele)           3   \n",
            "\n",
            "   Away Score     Home    Away  Outcome  Overs  \n",
            "0           2  Aladdin    Pele  Aladdin    4.5  \n",
            "1           4  Aladdin  Xerxes   Xerxes    4.5  \n",
            "2           1  Aladdin     Val  Aladdin    0.0  \n",
            "3           2  Aladdin   Panic    Panic    2.5  \n",
            "4           4  Aladdin    Pele     Pele    4.5  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1041 entries, 0 to 1040\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Match Time  1041 non-null   object \n",
            " 1   HomeTeam    1041 non-null   object \n",
            " 2   AwayTeam    1041 non-null   object \n",
            " 3   Home Score  1041 non-null   int64  \n",
            " 4   Away Score  1041 non-null   int64  \n",
            " 5   Home        1041 non-null   object \n",
            " 6   Away        1041 non-null   object \n",
            " 7   Outcome     1041 non-null   object \n",
            " 8   Overs       1041 non-null   float64\n",
            "dtypes: float64(1), int64(2), object(6)\n",
            "memory usage: 73.3+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e9c4030465045cf8a9189dfa9d03c15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='624' max='624' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [624/624 1:52:40, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.059298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.044350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.119800</td>\n",
              "      <td>0.040762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 02:24]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TeamA vs TeamB - Winner: Home - Overs: 20.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_gpt2/tokenizer_config.json',\n",
              " './fine_tuned_gpt2/special_tokens_map.json',\n",
              " './fine_tuned_gpt2/vocab.json',\n",
              " './fine_tuned_gpt2/merges.txt',\n",
              " './fine_tuned_gpt2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import os\n",
        "\n",
        "# Step 1: Load and inspect your Excel dataset\n",
        "file_path = '/Book.xlsx'  # Replace with the uploaded file path\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Inspect the first few rows to ensure it's loaded correctly\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Check for missing values and data types\n",
        "print(df.info())  # Check data types and missing values\n",
        "\n",
        "# If necessary, handle missing values by dropping or filling them\n",
        "df = df.dropna(subset=['Home', 'Away', 'Outcome', 'Overs'])  # Remove rows with any missing values in these columns\n",
        "\n",
        "# Ensure that 'Overs' is numeric (converting it to float if necessary)\n",
        "df['Overs'] = pd.to_numeric(df['Overs'], errors='coerce')  # Converts to NaN if conversion fails\n",
        "df = df.dropna(subset=['Overs'])  # Remove rows where 'Overs' is still NaN after conversion\n",
        "\n",
        "# Step 3: Preprocess the data to create a textual representation for each row\n",
        "# Combine Home, Away, Outcome, and Overs into a text description\n",
        "df['text'] = df['Home'] + \" vs \" + df['Away'] + \" - Winner: \" + df['Outcome'] + \" - Overs: \" + df['Overs'].astype(str)\n",
        "\n",
        "# Ensure there are no missing values in the 'text' column\n",
        "df = df.dropna(subset=['text'])\n",
        "\n",
        "# Step 4: Convert to Hugging Face Dataset format\n",
        "dataset = Dataset.from_pandas(df[['text']])  # Only include the 'text' column\n",
        "\n",
        "# Step 5: Initialize the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Add the padding token to the tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token # Using eos_token as pad_token\n",
        "\n",
        "# Step 6: Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    # Tokenizing the 'text' column\n",
        "    tokenized = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    # Create labels - shifted input_ids\n",
        "    tokenized['labels'] = tokenized['input_ids'].copy()  # Labels are the same as input_ids for language modeling\n",
        "    return tokenized\n",
        "\n",
        "# Apply the tokenize function to the dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Step 7: Split the dataset into training and validation sets\n",
        "train_dataset = tokenized_datasets.train_test_split(test_size=0.2)['train']\n",
        "val_dataset = tokenized_datasets.train_test_split(test_size=0.2)['test']\n",
        "\n",
        "# Step 8: Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Output directory for results\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate at the end of each epoch\n",
        "    per_device_train_batch_size=4,   # Batch size for training\n",
        "    per_device_eval_batch_size=4,    # Batch size for evaluation\n",
        "    num_train_epochs=3,              # Number of epochs to train\n",
        "    logging_dir=\"./logs\",            # Directory for logs\n",
        "    report_to=None\n",
        ")\n",
        "\n",
        "# Step 9: Initialize the GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Before initializing the Trainer, disable wandb environment variable\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Step 10: Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Step 11: Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Step 12: Evaluate the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Step 13: Use the model for text generation\n",
        "input_text = \"TeamA vs TeamB - Winner: Home - Overs: 20\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True) # Add padding=True here\n",
        "\n",
        "# Generate text (you can adjust max_length to control length of generated text)\n",
        "outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=100) # Pass attention_mask\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)\n",
        "\n",
        "# Step 14: Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained(\"./fine_tuned_gpt2\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_gpt2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./fine_tuned_gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./fine_tuned_gpt2\")\n",
        "\n",
        "# Read the excel file\n",
        "excel_file_path = '/content/Test.xlsx' # Replace with your excel file path\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "\n",
        "# Iterate through rows and generate predictions\n",
        "for index, row in df.iterrows():\n",
        "        home_team = row['Home']\n",
        "        away_team = row['Away']\n",
        "        input_text = f\"{home_team} vs {away_team}\"\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
        "        outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=100)\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        print(f\"Input: {input_text}, Prediction: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DorDss1IZpwz",
        "outputId": "6f3b39a6-2514-4d88-ca19-f93c20322c83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Panic vs Pele, Prediction: Panic vs Pele - Winner: Panic - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Thor vs Ivan, Prediction: Thor vs Ivan - Winner: Thor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Aladdin vs Xerxes, Prediction: Aladdin vs Xerxes - Winner: Xerxes - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Zangief vs Madisson, Prediction: Zangief vs Madisson - Winner: Madisson - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Panic vs Aladdin, Prediction: Panic vs Aladdin - Winner: Panic - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Thor vs Persie, Prediction: Thor vs Persie - Winner: Thor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Val vs Xerxes, Prediction: Val vs Xerxes - Winner: Xerxes - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Madisson vs Ivan, Prediction: Madisson vs Ivan - Winner: Madisson - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Pele vs Val, Prediction: Pele vs Val - Winner: Pele - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Madisson vs Thor, Prediction: Madisson vs Thor - Winner: Thor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Zangief vs Persie, Prediction: Zangief vs Persie - Winner: Zangief - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Panic vs Xerxes, Prediction: Panic vs Xerxes - Winner: Panic - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Aladdin vs Val, Prediction: Aladdin vs Val - Winner: Aladdin - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Ivan vs Zangief, Prediction: Ivan vs Zangief - Winner: Ivan - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Madisson vs Persie, Prediction: Madisson vs Persie - Winner: Madisson - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Pele vs Xerxes, Prediction: Pele vs Xerxes - Winner: Pele - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Pele vs Aladdin, Prediction: Pele vs Aladdin - Winner: Pele - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Panic vs Val, Prediction: Panic vs Val - Winner: Panic - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Thor vs Zangief, Prediction: Thor vs Zangief - Winner: Thor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Ivan vs Persie, Prediction: Ivan vs Persie - Winner: Persie - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Pele vs Panic, Prediction: Pele vs Panic - Winner: Pele - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Xerxes vs Aladdin, Prediction: Xerxes vs Aladdin - Winner: Xerxes - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Xerxes vs Val, Prediction: Xerxes vs Val - Winner: Xerxes - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Aladdin vs Panic, Prediction: Aladdin vs Panic - Winner: Aladdin - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Xerxes vs Panic, Prediction: Xerxes vs Panic - Winner: Xerxes - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Val vs Pele, Prediction: Val vs Pele - Winner: Val - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Val vs Aladdin, Prediction: Val vs Aladdin - Winner: Val - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Xerxes vs Pele, Prediction: Xerxes vs Pele - Winner: Xerxes - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Matrix vs Arthur, Prediction: Matrix vs Arthur - Winner: Professor - Overs: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Adriano vs Samuel, Prediction: Adriano vs Samuel - Winner: Aladdin - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Misterx vs Nathan, Prediction: Misterx vs Nathan - Winner: Professor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Sebastian vs Splinter, Prediction: Sebastian vs Splinter - Winner: Seagal - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Adriano vs Matrix, Prediction: Adriano vs Matrix - Winner: Adriano - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Logan vs Arthur, Prediction: Logan vs Arthur - Winner: Goliath - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Nathan vs Kai, Prediction: Nathan vs Kai - Winner: David - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Misterx vs Splinter, Prediction: Misterx vs Splinter - Winner: Professor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Samuel vs Logan, Prediction: Samuel vs Logan - Winner: Jack - Overs: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Adriano vs Arthur, Prediction: Adriano vs Arthur - Winner: Adriano - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Misterx vs Kai, Prediction: Misterx vs Kai - Winner: Professor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Nathan vs Sebastian, Prediction: Nathan vs Sebastian - Winner: Nathan - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Samuel vs Arthur, Prediction: Samuel vs Arthur - Winner: Jack - Overs: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Matrix vs Logan, Prediction: Matrix vs Logan - Winner: Professor - Overs: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Nathan vs Splinter, Prediction: Nathan vs Splinter - Winner: Drake - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Sebastian vs Kai, Prediction: Sebastian vs Kai - Winner: Seagal - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Sebastian vs Misterx, Prediction: Sebastian vs Misterx - Winner: Sebastian - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Splinter vs Kai, Prediction: Splinter vs Kai - Winner: Zangief - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Liam vs Mateo, Prediction: Liam vs Mateo - Winner: David - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Juan vs Oliver, Prediction: Juan vs Oliver - Winner: David - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Nathan vs Misterx, Prediction: Nathan vs Misterx - Winner: Nathan - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Splinter vs Sebastian, Prediction: Splinter vs Sebastian - Winner: Thor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Juan vs Liam, Prediction: Juan vs Liam - Winner: David - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Dominic vs Oliver, Prediction: Dominic vs Oliver - Winner: Carlos - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Kai vs Nathan, Prediction: Kai vs Nathan - Winner: Kai - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Splinter vs Misterx, Prediction: Splinter vs Misterx - Winner: Potter - Overs: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Dominic vs Mateo, Prediction: Dominic vs Mateo - Winner: Carlos - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Oliver vs Liam, Prediction: Oliver vs Liam - Winner: Oliver - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Kai vs Misterx, Prediction: Kai vs Misterx - Winner: Madisson - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Sebastian vs Nathan, Prediction: Sebastian vs Nathan - Winner: Sato - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Dominic vs Liam, Prediction: Dominic vs Liam - Winner: David - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Mateo vs Juan, Prediction: Mateo vs Juan - Winner: Molotov - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Dominic vs Juan, Prediction: Dominic vs Juan - Winner: Carlos - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Mateo vs Oliver, Prediction: Mateo vs Oliver - Winner: Molotov - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Mateo vs Liam, Prediction: Mateo vs Liam - Winner: Molotov - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Oliver vs Juan, Prediction: Oliver vs Juan - Winner: Thor - Overs: 4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Liam vs Juan, Prediction: Liam vs Juan - Winner: David - Overs: 4.5\n",
            "Input: Oliver vs Dominic, Prediction: Oliver vs Dominic - Winner: David - Overs: 4.5\n"
          ]
        }
      ]
    }
  ]
}